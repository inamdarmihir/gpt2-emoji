{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6266062,"sourceType":"datasetVersion","datasetId":156097}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)|\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-09T04:35:10.883750Z","iopub.execute_input":"2024-01-09T04:35:10.884403Z","iopub.status.idle":"2024-01-09T04:35:10.924434Z","shell.execute_reply.started":"2024-01-09T04:35:10.884371Z","shell.execute_reply":"2024-01-09T04:35:10.923617Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/emoji-data-descriptions-codepoints/emoji_testpage_screnshot.png\n/kaggle/input/emoji-data-descriptions-codepoints/emoji_df.csv\n/kaggle/input/emoji-data-descriptions-codepoints/emoji-test.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\nfrom transformers import DataCollatorForLanguageModeling\nfrom transformers import Trainer, TrainingArguments, GPT2LMHeadModel, GPT2Tokenizer\nfrom huggingface_hub import notebook_login\n\n# Install huggingface_hub if not installed\n!pip install huggingface_hub\n\n# Log in to the Hugging Face Hub\nnotebook_login()\n\ndef fine_tune_gpt2(dataset_path, model_name='gpt2', output_dir='./results', hub_model_name='my-awesome-model'):\n    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n    model = GPT2LMHeadModel.from_pretrained(model_name)\n\n    # Set the padding token\n    tokenizer.pad_token = tokenizer.eos_token\n\n    def tokenize_function(examples):\n        return tokenizer(examples[\"Text\"], padding=\"max_length\", truncation=True)\n\n    # Load the dataset and convert it to a format suitable for Dataset\n    df = pd.read_csv(dataset_path)\n    df['Text'] = df['name'] + ' ' + df['emoji']\n    dataset = Dataset.from_pandas(df)\n\n    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n    training_args = TrainingArguments(\n        output_dir=output_dir,\n        overwrite_output_dir=True,\n        num_train_epochs=2,  # Experiment with the number of epochs\n        per_device_train_batch_size=1,\n        save_steps=2000,  # Save model after every 2000 training steps\n        save_total_limit=2,\n        learning_rate=5e-5,  # Experiment with the learning rate\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        data_collator=data_collator,\n        train_dataset=tokenized_dataset,\n    )\n\n    # Train the model\n    trainer.train()\n\n    # Save the model and tokenizer locally\n    model.save_pretrained(output_dir)\n    tokenizer.save_pretrained(output_dir)\n\n    # Push the model and tokenizer to the Hugging Face Hub\n    model.push_to_hub(hub_model_name)\n    tokenizer.push_to_hub(hub_model_name)\n\n    print(f\"Model and tokenizer pushed to the Hub with the name: {hub_model_name}\")\n\nfine_tune_gpt2('/kaggle/input/emoji-data-descriptions-codepoints/emoji_df.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:19:56.992216Z","iopub.execute_input":"2024-01-09T05:19:56.992624Z","iopub.status.idle":"2024-01-09T05:59:34.048212Z","shell.execute_reply.started":"2024-01-09T05:19:56.992595Z","shell.execute_reply":"2024-01-09T05:59:34.046866Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.11.17)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb13391c1108453fa19c4face6645ffb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cac75da0d37430aa9c2cafca7d167d5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4724' max='4724' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4724/4724 39:03, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.742500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.142500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.956900</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.838600</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.685500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.291000</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.360000</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.356100</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.352800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory ./results/checkpoint-4000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73629972b22a4526800374d95d03ba4c"}},"metadata":{}},{"name":"stdout","text":"Model and tokenizer pushed to the Hub with the name: my-awesome-model\n","output_type":"stream"}]},{"cell_type":"code","source":"# Install huggingface_hub if not installed\n!pip install huggingface_hub\n\n# Log in to the Hugging Face Hub\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:17:59.262067Z","iopub.execute_input":"2024-01-09T05:17:59.262498Z","iopub.status.idle":"2024-01-09T05:18:11.090986Z","shell.execute_reply.started":"2024-01-09T05:17:59.262443Z","shell.execute_reply":"2024-01-09T05:18:11.089696Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.11.17)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6995390836d54415800007c7d177f8ed"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\ndef generate_emoji(text, model_path='./results'):\n    tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n    model = GPT2LMHeadModel.from_pretrained(model_path)\n    generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n    result = generator(text, max_length=50, do_sample=True, temperature=0.7)\n    return result[0]['generated_text']\n\n# Test the model\nprint(generate_emoji('What is up?'))","metadata":{"execution":{"iopub.status.busy":"2024-01-09T06:30:03.052897Z","iopub.execute_input":"2024-01-09T06:30:03.053722Z","iopub.status.idle":"2024-01-09T06:30:05.258612Z","shell.execute_reply.started":"2024-01-09T06:30:03.053693Z","shell.execute_reply":"2024-01-09T06:30:05.257522Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What is up? ðŸ—˜ï¸â€ðŸ”§ï¸â€ðŸ§‘â€ðŸ§‘â€ðŸ§‘â€ðŸ§‘â€ðŸ§‘â€ðŸ§‘â€ðŸ§‘ï¿½\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}